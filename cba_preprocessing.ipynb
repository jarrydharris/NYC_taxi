{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdcbcf8e-62ec-4d85-876c-e1abdeb854cf",
   "metadata": {},
   "source": [
    "# Preprocessing NYC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0158608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "\n",
    "import datetime as dt\n",
    "import calendar\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from shapely.geometry import Point\n",
    "import dask.dataframe as dd\n",
    "import dask.distributed\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875929c5",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e153c9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_fare = pd.read_csv(\"data/trip_fare_4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79f6caf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jarryd/Documents/python/Environment/cba/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3457: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "clean_data = pd.read_csv(\"data/trip_data_4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcc8f5e",
   "metadata": {},
   "source": [
    "The files were too big for pandas to automatically assign the best data types, will need to do that manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b913f766",
   "metadata": {},
   "source": [
    "# Initial data inspection and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be7d713",
   "metadata": {},
   "source": [
    "## Checking the variable names and dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02b65a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['medallion', ' hack_license', ' vendor_id', ' pickup_datetime',\n",
       "       ' payment_type', ' fare_amount', ' surcharge', ' mta_tax',\n",
       "       ' tip_amount', ' tolls_amount', ' total_amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_fare.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068cd15a",
   "metadata": {},
   "source": [
    "Visual inspection of the column names shows there is unnecessary whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7268d531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the whitespace in column names\n",
    "clean_fare.columns = clean_fare.columns.str.replace(\" \", \"\")\n",
    "clean_data.columns = clean_data.columns.str.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e55194f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change columns to a category\n",
    "clean_fare[\"medallion\"] = clean_fare[\"medallion\"].astype(\"category\")\n",
    "clean_fare[\"hack_license\"] = clean_fare[\"hack_license\"].astype(\"category\")\n",
    "\n",
    "clean_fare.vendor_id.unique() # Only 2 types \"CMT\" and \"VTF\"\n",
    "clean_fare[\"vendor_id\"] = clean_fare[\"vendor_id\"].astype(\"category\")\n",
    "\n",
    "clean_fare.payment_type.unique() # 'CRD', 'CSH', 'UNK', 'NOC', 'DIS'\n",
    "clean_fare[\"payment_type\"] = clean_fare[\"payment_type\"].astype(\"category\")\n",
    "\n",
    "# Change type to datetime \n",
    "clean_fare[\"pickup_datetime\"] = clean_fare[\"pickup_datetime\"].astype(\"datetime64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25c1e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change columns to a category\n",
    "clean_data[\"medallion\"] = clean_data[\"medallion\"].astype(\"category\")\n",
    "clean_data[\"hack_license\"] = clean_data[\"hack_license\"].astype(\"category\")\n",
    "\n",
    "clean_data.vendor_id.unique() # Only 2 types \"CMT\" and \"VTF\"\n",
    "clean_data[\"vendor_id\"] = clean_data[\"vendor_id\"].astype(\"category\")\n",
    "\n",
    "clean_data.rate_code.unique() # 0-9 and 65, 77, 206, 208, 210\n",
    "clean_data[\"rate_code\"] = clean_data[\"rate_code\"].astype(\"category\")\n",
    "\n",
    "clean_data.store_and_fwd_flag.unique() # Y, N, NA\n",
    "clean_data[\"store_and_fwd_flag\"] = clean_data[\"store_and_fwd_flag\"].astype(\"category\")\n",
    "\n",
    "# Change type to datetime \n",
    "clean_data[\"pickup_datetime\"] = clean_data[\"pickup_datetime\"].astype(\"datetime64\")\n",
    "clean_data[\"dropoff_datetime\"] = clean_data[\"dropoff_datetime\"].astype(\"datetime64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2f42a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcaster(df):\n",
    "    \"\"\"\n",
    "    Checks the dtype of each numerical variable and downcasts to the lowest \n",
    "    memory usage datatype possible\n",
    "    \n",
    "    param: \n",
    "        df: pandas.core.frame.DataFrame\n",
    "    \n",
    "    returns: \n",
    "        the downcasted dataframe\n",
    "    \"\"\"\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == \"int\":\n",
    "            downcast_type = \"integer\"\n",
    "        elif df[column].dtype == \"float\":\n",
    "            downcast_type = \"float\"\n",
    "        else:\n",
    "            continue\n",
    "        df[column] = pd.to_numeric(df[column], \n",
    "                                   errors='ignore', \n",
    "                                   downcast=downcast_type)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7763dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downcasting to make things less memory intensive\n",
    "clean_data = downcaster(clean_data)\n",
    "clean_fare = downcaster(clean_fare)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ca4797",
   "metadata": {},
   "source": [
    "Saved a few gb of memory!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7c27e1",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e4abc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medallion          0\n",
       "hack_license       0\n",
       "vendor_id          0\n",
       "pickup_datetime    0\n",
       "payment_type       0\n",
       "fare_amount        0\n",
       "surcharge          0\n",
       "mta_tax            0\n",
       "tip_amount         0\n",
       "tolls_amount       0\n",
       "total_amount       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_fare.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d660cf2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medallion                   0\n",
       "hack_license                0\n",
       "vendor_id                   0\n",
       "rate_code                   0\n",
       "store_and_fwd_flag    7518657\n",
       "pickup_datetime             0\n",
       "dropoff_datetime            0\n",
       "passenger_count             0\n",
       "trip_time_in_secs           0\n",
       "trip_distance               0\n",
       "pickup_longitude            0\n",
       "pickup_latitude             0\n",
       "dropoff_longitude         146\n",
       "dropoff_latitude          146\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d620aa26",
   "metadata": {},
   "source": [
    "Only missing values are relating to coordinates and store and fwd flag (this relates to when the fare system is down and the taxi driver needs to store the fare and upload it later, assuming NA means the system was functioning)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfabbaf",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81c75bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>surcharge</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15100468.00</td>\n",
       "      <td>15100468.00</td>\n",
       "      <td>15100468.00</td>\n",
       "      <td>15100468.00</td>\n",
       "      <td>15100468.00</td>\n",
       "      <td>15100468.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.27</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.24</td>\n",
       "      <td>14.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.96</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.13</td>\n",
       "      <td>1.19</td>\n",
       "      <td>11.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>200.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>628.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fare_amount    surcharge      mta_tax   tip_amount tolls_amount  \\\n",
       "count  15100468.00  15100468.00  15100468.00  15100468.00  15100468.00   \n",
       "mean         12.27         0.33         0.50         1.35         0.24   \n",
       "std           9.96         0.37         0.03         2.13         1.19   \n",
       "min           2.50         0.00         0.00         0.00         0.00   \n",
       "25%           6.50         0.00         0.50         0.00         0.00   \n",
       "50%           9.50         0.00         0.50         1.00         0.00   \n",
       "75%          14.00         0.50         0.50         2.00         0.00   \n",
       "max         500.00        15.00         0.50       200.00        20.00   \n",
       "\n",
       "      total_amount  \n",
       "count  15100468.00  \n",
       "mean         14.69  \n",
       "std          11.94  \n",
       "min           2.50  \n",
       "25%           8.00  \n",
       "50%          11.00  \n",
       "75%          16.50  \n",
       "max         628.10  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_fare.describe().apply(lambda s: s.apply('{0:.2f}'.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62010179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_time_in_secs</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15100468.00</td>\n",
       "      <td>15100468.00</td>\n",
       "      <td>15100468.00</td>\n",
       "      <td>15100468.00</td>\n",
       "      <td>15100468.00</td>\n",
       "      <td>15100322.00</td>\n",
       "      <td>15100322.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.71</td>\n",
       "      <td>746.61</td>\n",
       "      <td>2.86</td>\n",
       "      <td>-72.73</td>\n",
       "      <td>40.07</td>\n",
       "      <td>-72.69</td>\n",
       "      <td>40.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.39</td>\n",
       "      <td>550.44</td>\n",
       "      <td>3.34</td>\n",
       "      <td>9.73</td>\n",
       "      <td>6.96</td>\n",
       "      <td>9.86</td>\n",
       "      <td>6.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2323.42</td>\n",
       "      <td>-3481.14</td>\n",
       "      <td>-2771.29</td>\n",
       "      <td>-3547.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>360.00</td>\n",
       "      <td>1.04</td>\n",
       "      <td>-73.99</td>\n",
       "      <td>40.74</td>\n",
       "      <td>-73.99</td>\n",
       "      <td>40.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>600.00</td>\n",
       "      <td>1.78</td>\n",
       "      <td>-73.98</td>\n",
       "      <td>40.75</td>\n",
       "      <td>-73.98</td>\n",
       "      <td>40.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.00</td>\n",
       "      <td>960.00</td>\n",
       "      <td>3.20</td>\n",
       "      <td>-73.97</td>\n",
       "      <td>40.77</td>\n",
       "      <td>-73.96</td>\n",
       "      <td>40.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.00</td>\n",
       "      <td>10800.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>2228.72</td>\n",
       "      <td>3210.39</td>\n",
       "      <td>2228.75</td>\n",
       "      <td>3577.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      passenger_count trip_time_in_secs trip_distance pickup_longitude  \\\n",
       "count     15100468.00       15100468.00   15100468.00      15100468.00   \n",
       "mean             1.71            746.61          2.86           -72.73   \n",
       "std              1.39            550.44          3.34             9.73   \n",
       "min              0.00              0.00          0.00         -2323.42   \n",
       "25%              1.00            360.00          1.04           -73.99   \n",
       "50%              1.00            600.00          1.78           -73.98   \n",
       "75%              2.00            960.00          3.20           -73.97   \n",
       "max              9.00          10800.00        100.00          2228.72   \n",
       "\n",
       "      pickup_latitude dropoff_longitude dropoff_latitude  \n",
       "count     15100468.00       15100322.00      15100322.00  \n",
       "mean            40.07            -72.69            40.05  \n",
       "std              6.96              9.86             6.98  \n",
       "min          -3481.14          -2771.29         -3547.90  \n",
       "25%             40.74            -73.99            40.73  \n",
       "50%             40.75            -73.98            40.75  \n",
       "75%             40.77            -73.96            40.77  \n",
       "max           3210.39           2228.75          3577.13  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.describe().apply(lambda s: s.apply('{0:.2f}'.format))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8858a609",
   "metadata": {},
   "source": [
    "**Passenger count**\n",
    "\n",
    "0 passengers is most likely an error. There are 33 of these entries.\n",
    "\n",
    "**Trip time**\n",
    "\n",
    "The minimum trip time is 0, this is most likely due to negotiated trips not being entered in the system in the standard way.\n",
    "\n",
    "**Trip distance**\n",
    "\n",
    "The same as trip time.\n",
    "\n",
    "**Coords**\n",
    "\n",
    "Standard coordinatess are between -90 to 90 for latitude and -180 to 180 for longitude. Anything outside this range should be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24913f17-7e9b-4f73-bbe7-0eb5c315bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking for the number of rows with out of bounds coordinates\n",
    "dropoff_longitude_bounds = ((clean_data[\"dropoff_longitude\"] < -180) | \n",
    "                            (clean_data[\"dropoff_longitude\"] > 180))\n",
    "dropoff_latitude_bounds = ((clean_data[\"dropoff_latitude\"] < -90) | \n",
    "                           (clean_data[\"dropoff_latitude\"] > 90))\n",
    "pickup_longitude_bounds = ((clean_data[\"pickup_longitude\"] < -180) | \n",
    "                           (clean_data[\"pickup_longitude\"] > 180))\n",
    "pickup_latitude_bounds = ((clean_data[\"pickup_latitude\"] < -90) | \n",
    "                          (clean_data[\"pickup_latitude\"] > 90))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16b0ded",
   "metadata": {},
   "source": [
    "## Saving for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "764c4402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving dataframes as a python object to use in another notebook\n",
    "clean_fare.to_pickle('data/clean_fare.pickle')\n",
    "clean_data.to_pickle('data/clean_data.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138ff28a-c21b-45cb-bfa9-991f3f77b711",
   "metadata": {},
   "source": [
    "## Labeling the pickup and dropoff zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebf9b4de-9285-4419-91ab-26a3733bcb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a dashboard to view the progress of dask computations\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bbd5d1e-c445-416d-949b-1605912b5f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_zone(df, longitude, latitude, location_id):\n",
    "    \"\"\"Used in conjunction with map_partition() to map a set of coordinates\n",
    "    (longitutde and latitude) to a zone id (number relating to a place in manhatten).\n",
    "    \n",
    "    params:\n",
    "        df: pandas.core.frame.DataFrame\n",
    "        longitude: float\n",
    "        latitude: float\n",
    "        location_id: int\n",
    "    \n",
    "    returns:\n",
    "        geopandas.GeoDataFrame\n",
    "    \"\"\"\n",
    "    local_df = df[[longitude, latitude]].copy()\n",
    "    local_gdf = gpd.GeoDataFrame(local_df, \n",
    "                                 crs=4326,\n",
    "                                 geometry=[Point(xy) for xy in \n",
    "                                           zip(local_df[longitude], \n",
    "                                               local_df[latitude])])\n",
    "    zones = gpd.read_file(\"data/shapefile/taxi_zones.shp\")\n",
    "    zones = zones[['LocationID', 'geometry']]\n",
    "    zones = zones.to_crs(crs=4326)\n",
    "    local_gdf = gpd.sjoin(local_gdf, \n",
    "                                zones, \n",
    "                                how='left',\n",
    "                                predicate='within')\n",
    "    \n",
    "    return local_gdf.LocationID.rename(location_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfad0f62-3694-461f-a2c6-ffd840ffce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data and transforming to new coord system\n",
    "# Will be used to match long, lat coordinates to zone names\n",
    "taxi_zones = gpd.read_file(\"data/shapefile/taxi_zones.shp\")\n",
    "taxi_zones['zone'] = taxi_zones.zone.astype('category')\n",
    "taxi_zones['borough'] = taxi_zones.borough.astype('category')\n",
    "taxi_zones = taxi_zones.to_crs(crs=4326)\n",
    "taxi_zones = taxi_zones[[\"zone\",\"borough\", \"LocationID\"]]\n",
    "taxi_zones[\"LocationID\"] = taxi_zones[\"LocationID\"].astype(\"int16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0511bd4f-2866-4090-99bd-f779775f4b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all data outside of manhatten (-74.26, 40.47, -71.8, 41.3)\n",
    "pickup_longitude_bounds = ((clean_data[\"pickup_longitude\"] >= -74.26) & \n",
    "                           (clean_data[\"pickup_longitude\"] <= -71.8))\n",
    "pickup_latitude_bounds = ((clean_data[\"pickup_latitude\"] >= 40.47) & \n",
    "                          (clean_data[\"pickup_latitude\"] <= 41.3))\n",
    "\n",
    "dropoff_longitude_bounds = ((clean_data[\"dropoff_longitude\"] >= -74.26) & \n",
    "                            (clean_data[\"dropoff_longitude\"] <= -71.8))\n",
    "dropoff_latitude_bounds = ((clean_data[\"dropoff_latitude\"] >= 40.47) & \n",
    "                           (clean_data[\"dropoff_latitude\"] <= 41.3))\n",
    "\n",
    "clean_data = dd.from_pandas(clean_data[dropoff_longitude_bounds & \n",
    "                                       dropoff_latitude_bounds &\n",
    "                                       pickup_longitude_bounds &\n",
    "                                       pickup_latitude_bounds],\n",
    "                           npartitions=16) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0890309-83b0-4acd-958c-ccba55924614",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "map_partition is a dask dataframe method that partitions the dataframe in to a number\n",
    "of smaller pandas dataframes and applies functions to them one after the other. \n",
    "It is lazy, which means it never loads or shows data until it is needed for computation\n",
    "this means we only use memory as it is needed. Great for doing computationally intense \n",
    "operations on large datasets.\n",
    "\"\"\"\n",
    "\n",
    "clean_data['pickup_id'] = clean_data.map_partitions(\n",
    "    assign_zone, \n",
    "    longitude = \"pickup_longitude\", \n",
    "    latitude = \"pickup_latitude\", \n",
    "    location_id = \"pickup_id\", meta=('pickup_id',np.int16))\n",
    "\n",
    "clean_data['dropoff_id'] = clean_data.map_partitions(\n",
    "    assign_zone, \n",
    "    longitude = \"dropoff_longitude\", \n",
    "    latitude = \"dropoff_latitude\", \n",
    "    location_id = \"dropoff_id\", meta=('dropoff_id',np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b80240a-925d-4a08-af55-790d2ef87ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For some reason using dask to write the map_partition results to parquet (a file format \n",
    "used by apache) and then reading it back from a file to a pandas dataframe is (much) \n",
    "faster than transforming a dask dataframe to a pandas dataframe. This could be due to:\n",
    "1. The fact I'm not a dask expert and I'm doing something wrong.\n",
    "2. It's easier to compute in memory and write to disk then compute in memory and \n",
    "store in memory. If I had to do this more often I'd do some reading to see if there \n",
    "was something I could do to speed up transforming dask to pandas\n",
    "\"\"\"\n",
    "\n",
    "compute_dask = False\n",
    "\n",
    "if compute_dask:\n",
    "    clean_data.to_parquet('data/trips.parquet')\n",
    "\n",
    "clean_data = pd.read_parquet('data/trips.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79f21f1f-252e-4857-8cc0-993f12be33ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "assign_zone() outputs the pickup zones as floats, to lower the ram usage and get rid\n",
    "of the decimal we need to fill the nans with a negative number (all the zone ids are\n",
    "positive) and then change to an int16, after this we can drop any row that has \n",
    "coordinates which assign_zone() output nan. Given more time I'd investigate why nans\n",
    "were output but its simpler just to ignore them given the amount of data left over.\n",
    "\"\"\"\n",
    "\n",
    "clean_data[\"pickup_id\"] = clean_data[\"pickup_id\"].fillna(-1)\n",
    "clean_data[\"dropoff_id\"] = clean_data[\"dropoff_id\"].fillna(-1)\n",
    "clean_data[\"pickup_id\"] = clean_data[\"pickup_id\"].astype(\"int16\")\n",
    "clean_data[\"dropoff_id\"] = clean_data[\"dropoff_id\"].astype(\"int16\")\n",
    "clean_data = clean_data[(clean_data[\"pickup_id\"] > 0) &\n",
    "                       (clean_data[\"dropoff_id\"] > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e1053b-d4b5-4194-ba43-771eea58c95a",
   "metadata": {},
   "source": [
    "## Merge the data and fare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c1abfe8-d4e9-4164-a5b3-dd7db9ea85d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the data and fare dataframes and changing column dtypes\n",
    "clean_data = clean_data.merge(taxi_zones\n",
    "                              .rename(columns={\"LocationID\":\"pickup_id\",\n",
    "                                              \"zone\":\"pickup_zone\",\n",
    "                                              \"borough\":\"pickup_borough\"}),\n",
    "                              on=\"pickup_id\",\n",
    "                              how=\"left\")\n",
    "clean_data = clean_data.merge(taxi_zones\n",
    "                              .rename(columns={\"LocationID\":\"dropoff_id\",\n",
    "                                              \"zone\":\"dropoff_zone\",\n",
    "                                              \"borough\":\"dropoff_borough\"}),\n",
    "                              on=\"dropoff_id\",\n",
    "                              how=\"left\")\n",
    "for column in [\"pickup_zone\", \"pickup_borough\", \"dropoff_zone\", \"dropoff_borough\"]:\n",
    "    clean_data[column] = clean_data[column].astype(\"category\")\n",
    "    \n",
    "clean_data[\"trip\"] = (clean_data[\"pickup_zone\"]\n",
    "                      .astype(\"string\")\n",
    "                      .str\n",
    "                      .cat(clean_data[\"dropoff_zone\"]\n",
    "                           .astype(\"string\"), \n",
    "                           sep=\" to \"))\n",
    "clean_data[\"trip\"] = clean_data[\"trip\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32e43515-4594-42d2-abad-958ec835821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of variables that match in both dataframes and join on them\n",
    "join_variables = (set(clean_data\n",
    "                      .columns\n",
    "                      .values)\n",
    "                  .intersection(set(clean_fare\n",
    "                                    .columns\n",
    "                                    .values)))\n",
    "merged_data = clean_data.merge(clean_fare,\n",
    "                                   on=list(join_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a81a6df-9f73-4635-94b7-1157a347353b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "# Creating new features for the open ended questions\n",
    "merged_data['pickup_hour'] = merged_data['pickup_datetime'].apply(lambda x:x.hour)\n",
    "merged_data['dropoff_hour'] = merged_data['dropoff_datetime'].apply(lambda x:x.hour)\n",
    "merged_data['pickup_day'] = (merged_data['pickup_datetime'].apply(lambda x:calendar.day_name[x.weekday()])\n",
    "                   .astype(\"category\"))\n",
    "merged_data['earnings'] = merged_data[\"fare_amount\"] + merged_data[\"tip_amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3e6f00b-7d9b-4bd7-8f1f-9d7054991db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downcasting new features\n",
    "merged_data['pickup_hour'] = pd.to_numeric(merged_data['pickup_hour'], \n",
    "                                   errors='ignore', \n",
    "                                   downcast=\"integer\")\n",
    "merged_data['dropoff_hour'] = pd.to_numeric(merged_data['dropoff_hour'], \n",
    "                                   errors='ignore', \n",
    "                                   downcast=\"integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "971ae9d0-449e-460d-83d1-a60f2f427294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving for later use.\n",
    "merged_data.to_pickle('data/merged_data.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
